{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the data\n",
    "train_csv = \"train.csv\"\n",
    "test_csv = \"test.csv\"\n",
    "train = pd.read_csv(train_csv)\n",
    "test = pd.read_csv(test_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset: Index(['tBodyAcc-mean()-X', 'tBodyAcc-mean()-Y', 'tBodyAcc-mean()-Z',\n",
      "       'tBodyAcc-std()-X', 'tBodyAcc-std()-Y', 'tBodyAcc-std()-Z',\n",
      "       'tBodyAcc-mad()-X', 'tBodyAcc-mad()-Y', 'tBodyAcc-mad()-Z',\n",
      "       'tBodyAcc-max()-X',\n",
      "       ...\n",
      "       'fBodyBodyGyroJerkMag-kurtosis()', 'angle(tBodyAccMean,gravity)',\n",
      "       'angle(tBodyAccJerkMean),gravityMean)',\n",
      "       'angle(tBodyGyroMean,gravityMean)',\n",
      "       'angle(tBodyGyroJerkMean,gravityMean)', 'angle(X,gravityMean)',\n",
      "       'angle(Y,gravityMean)', 'angle(Z,gravityMean)', 'subject', 'Activity'],\n",
      "      dtype='object', length=563)\n",
      "Number of columns: 563\n"
     ]
    }
   ],
   "source": [
    "# Inspect the data\n",
    "print(\"Columns in the dataset:\", train.columns)\n",
    "print(\"Number of columns:\", len(train.columns))\n",
    "\n",
    "# Separate features and labels\n",
    "X_train = train.iloc[:, :-2]  # Exclude 'subject' and 'Activity'\n",
    "X_test = test.iloc[:, :-2]\n",
    "y_train = train['Activity']\n",
    "y_test = test['Activity']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: LogisticRegression\n",
      "Accuracy: 95.45%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       537\n",
      "           1       0.97      0.88      0.92       491\n",
      "           2       0.89      0.97      0.93       532\n",
      "           3       0.94      0.99      0.97       496\n",
      "           4       0.99      0.94      0.96       420\n",
      "           5       0.96      0.95      0.95       471\n",
      "\n",
      "    accuracy                           0.95      2947\n",
      "   macro avg       0.96      0.95      0.95      2947\n",
      "weighted avg       0.96      0.95      0.95      2947\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9545300305395318"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define and evaluate different models\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"\\nModel: {model.__class__.__name__}\")\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n",
    "    return accuracy\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "evaluate_model(log_reg, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: RandomForestClassifier\n",
      "Accuracy: 92.67%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       537\n",
      "           1       0.91      0.90      0.90       491\n",
      "           2       0.91      0.92      0.91       532\n",
      "           3       0.89      0.97      0.93       496\n",
      "           4       0.96      0.87      0.91       420\n",
      "           5       0.90      0.89      0.90       471\n",
      "\n",
      "    accuracy                           0.93      2947\n",
      "   macro avg       0.93      0.92      0.93      2947\n",
      "weighted avg       0.93      0.93      0.93      2947\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9267051238547676"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "evaluate_model(rf, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: GradientBoostingClassifier\n",
      "Accuracy: 93.96%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       537\n",
      "           1       0.93      0.86      0.89       491\n",
      "           2       0.88      0.94      0.91       532\n",
      "           3       0.94      0.98      0.96       496\n",
      "           4       0.97      0.92      0.95       420\n",
      "           5       0.93      0.93      0.93       471\n",
      "\n",
      "    accuracy                           0.94      2947\n",
      "   macro avg       0.94      0.94      0.94      2947\n",
      "weighted avg       0.94      0.94      0.94      2947\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9395995928062436"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Gradient Boosting\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "evaluate_model(gb, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: SVC\n",
      "Accuracy: 95.18%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       537\n",
      "           1       0.94      0.90      0.92       491\n",
      "           2       0.92      0.95      0.93       532\n",
      "           3       0.96      0.97      0.97       496\n",
      "           4       0.98      0.92      0.95       420\n",
      "           5       0.93      0.97      0.95       471\n",
      "\n",
      "    accuracy                           0.95      2947\n",
      "   macro avg       0.95      0.95      0.95      2947\n",
      "weighted avg       0.95      0.95      0.95      2947\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9518154054971157"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Support Vector Machine\n",
    "svm = SVC(kernel='rbf', probability=True)\n",
    "evaluate_model(svm, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: KNeighborsClassifier\n",
      "Accuracy: 88.36%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       537\n",
      "           1       0.88      0.76      0.82       491\n",
      "           2       0.80      0.93      0.86       532\n",
      "           3       0.82      0.97      0.89       496\n",
      "           4       0.95      0.75      0.84       420\n",
      "           5       0.90      0.89      0.89       471\n",
      "\n",
      "    accuracy                           0.88      2947\n",
      "   macro avg       0.89      0.88      0.88      2947\n",
      "weighted avg       0.89      0.88      0.88      2947\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8836104513064132"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "evaluate_model(knn, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devdr\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Neural Network...\n",
      "Epoch 1/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6866 - loss: 0.8155 - val_accuracy: 0.9286 - val_loss: 0.1989\n",
      "Epoch 2/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.2218 - val_accuracy: 0.9266 - val_loss: 0.2310\n",
      "Epoch 3/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9493 - loss: 0.1280 - val_accuracy: 0.9361 - val_loss: 0.1701\n",
      "Epoch 4/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9571 - loss: 0.1161 - val_accuracy: 0.9409 - val_loss: 0.1703\n",
      "Epoch 5/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9697 - loss: 0.0839 - val_accuracy: 0.9511 - val_loss: 0.1189\n",
      "Epoch 6/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9684 - loss: 0.0783 - val_accuracy: 0.9463 - val_loss: 0.1472\n",
      "Epoch 7/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9698 - loss: 0.0739 - val_accuracy: 0.9415 - val_loss: 0.2002\n",
      "Epoch 8/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9768 - loss: 0.0601 - val_accuracy: 0.9443 - val_loss: 0.1716\n",
      "Epoch 9/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9756 - loss: 0.0702 - val_accuracy: 0.9402 - val_loss: 0.2270\n",
      "Epoch 10/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9795 - loss: 0.0538 - val_accuracy: 0.9381 - val_loss: 0.2098\n",
      "Epoch 11/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9794 - loss: 0.0550 - val_accuracy: 0.9517 - val_loss: 0.1564\n",
      "Epoch 12/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9831 - loss: 0.0524 - val_accuracy: 0.9538 - val_loss: 0.1492\n",
      "Epoch 13/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9778 - loss: 0.0516 - val_accuracy: 0.9511 - val_loss: 0.1412\n",
      "Epoch 14/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9864 - loss: 0.0459 - val_accuracy: 0.9517 - val_loss: 0.1440\n",
      "Epoch 15/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9841 - loss: 0.0401 - val_accuracy: 0.9456 - val_loss: 0.1965\n",
      "Epoch 16/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9875 - loss: 0.0462 - val_accuracy: 0.9524 - val_loss: 0.1380\n",
      "Epoch 17/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9843 - loss: 0.0452 - val_accuracy: 0.9483 - val_loss: 0.1846\n",
      "Epoch 18/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9861 - loss: 0.0407 - val_accuracy: 0.9497 - val_loss: 0.1653\n",
      "Epoch 19/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9835 - loss: 0.0481 - val_accuracy: 0.9470 - val_loss: 0.1777\n",
      "Epoch 20/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9879 - loss: 0.0338 - val_accuracy: 0.9524 - val_loss: 0.1598\n",
      "Epoch 21/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9860 - loss: 0.0403 - val_accuracy: 0.9545 - val_loss: 0.1676\n",
      "Epoch 22/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9913 - loss: 0.0267 - val_accuracy: 0.9443 - val_loss: 0.1919\n",
      "Epoch 23/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9860 - loss: 0.0409 - val_accuracy: 0.9538 - val_loss: 0.2094\n",
      "Epoch 24/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9819 - loss: 0.0557 - val_accuracy: 0.9551 - val_loss: 0.1553\n",
      "Epoch 25/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9894 - loss: 0.0314 - val_accuracy: 0.9551 - val_loss: 0.1741\n",
      "Epoch 26/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9893 - loss: 0.0298 - val_accuracy: 0.9517 - val_loss: 0.1364\n",
      "Epoch 27/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0211 - val_accuracy: 0.9599 - val_loss: 0.1830\n",
      "Epoch 28/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0140 - val_accuracy: 0.9572 - val_loss: 0.1834\n",
      "Epoch 29/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9895 - loss: 0.0278 - val_accuracy: 0.9531 - val_loss: 0.2149\n",
      "Epoch 30/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9900 - loss: 0.0277 - val_accuracy: 0.9599 - val_loss: 0.1755\n",
      "Epoch 31/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9889 - loss: 0.0274 - val_accuracy: 0.9524 - val_loss: 0.1943\n",
      "Epoch 32/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9873 - loss: 0.0355 - val_accuracy: 0.9585 - val_loss: 0.1332\n",
      "Epoch 33/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0214 - val_accuracy: 0.9592 - val_loss: 0.1700\n",
      "Epoch 34/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9912 - loss: 0.0270 - val_accuracy: 0.9599 - val_loss: 0.1477\n",
      "Epoch 35/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9940 - loss: 0.0172 - val_accuracy: 0.9558 - val_loss: 0.2017\n",
      "Epoch 36/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9902 - loss: 0.0361 - val_accuracy: 0.9517 - val_loss: 0.2461\n",
      "Epoch 37/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9893 - loss: 0.0307 - val_accuracy: 0.9599 - val_loss: 0.1853\n",
      "Epoch 38/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9934 - loss: 0.0179 - val_accuracy: 0.9613 - val_loss: 0.1975\n",
      "Epoch 39/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9927 - loss: 0.0247 - val_accuracy: 0.9592 - val_loss: 0.1865\n",
      "Epoch 40/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9963 - loss: 0.0123 - val_accuracy: 0.9565 - val_loss: 0.2222\n",
      "Epoch 41/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9959 - loss: 0.0127 - val_accuracy: 0.9619 - val_loss: 0.1901\n",
      "Epoch 42/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9963 - loss: 0.0124 - val_accuracy: 0.9585 - val_loss: 0.1735\n",
      "Epoch 43/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9958 - loss: 0.0138 - val_accuracy: 0.9517 - val_loss: 0.2196\n",
      "Epoch 44/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9870 - loss: 0.0490 - val_accuracy: 0.9511 - val_loss: 0.2204\n",
      "Epoch 45/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9938 - loss: 0.0199 - val_accuracy: 0.9524 - val_loss: 0.2692\n",
      "Epoch 46/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9950 - loss: 0.0173 - val_accuracy: 0.9606 - val_loss: 0.1958\n",
      "Epoch 47/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0185 - val_accuracy: 0.9538 - val_loss: 0.2556\n",
      "Epoch 48/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9906 - loss: 0.0259 - val_accuracy: 0.9558 - val_loss: 0.1883\n",
      "Epoch 49/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0201 - val_accuracy: 0.9619 - val_loss: 0.2299\n",
      "Epoch 50/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9952 - loss: 0.0135 - val_accuracy: 0.9585 - val_loss: 0.1897\n",
      "\n",
      "Model: Neural Network\n",
      "Accuracy: 93.86%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Neural Network\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train_nn = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_nn = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "nn = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "nn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"\\nTraining Neural Network...\")\n",
    "nn.fit(X_train, y_train_nn, epochs=50, batch_size=32, verbose=1, validation_split=0.2)\n",
    "\n",
    "# Evaluate Neural Network\n",
    "nn_loss, nn_accuracy = nn.evaluate(X_test, y_test_nn, verbose=0)\n",
    "print(f\"\\nModel: Neural Network\")\n",
    "print(f\"Accuracy: {nn_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset: Index(['tBodyAcc-mean()-X', 'tBodyAcc-mean()-Y', 'tBodyAcc-mean()-Z',\n",
      "       'tBodyAcc-std()-X', 'tBodyAcc-std()-Y', 'tBodyAcc-std()-Z',\n",
      "       'tBodyAcc-mad()-X', 'tBodyAcc-mad()-Y', 'tBodyAcc-mad()-Z',\n",
      "       'tBodyAcc-max()-X',\n",
      "       ...\n",
      "       'fBodyBodyGyroJerkMag-kurtosis()', 'angle(tBodyAccMean,gravity)',\n",
      "       'angle(tBodyAccJerkMean),gravityMean)',\n",
      "       'angle(tBodyGyroMean,gravityMean)',\n",
      "       'angle(tBodyGyroJerkMean,gravityMean)', 'angle(X,gravityMean)',\n",
      "       'angle(Y,gravityMean)', 'angle(Z,gravityMean)', 'subject', 'Activity'],\n",
      "      dtype='object', length=563)\n",
      "Number of columns: 563\n",
      "\n",
      "Model: LogisticRegression\n",
      "Accuracy: 95.45%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       537\n",
      "           1       0.97      0.88      0.92       491\n",
      "           2       0.89      0.97      0.93       532\n",
      "           3       0.94      0.99      0.97       496\n",
      "           4       0.99      0.94      0.96       420\n",
      "           5       0.96      0.95      0.95       471\n",
      "\n",
      "    accuracy                           0.95      2947\n",
      "   macro avg       0.96      0.95      0.95      2947\n",
      "weighted avg       0.96      0.95      0.95      2947\n",
      "\n",
      "\n",
      "Model: RandomForestClassifier\n",
      "Accuracy: 92.67%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       537\n",
      "           1       0.91      0.90      0.90       491\n",
      "           2       0.91      0.92      0.91       532\n",
      "           3       0.89      0.97      0.93       496\n",
      "           4       0.96      0.87      0.91       420\n",
      "           5       0.90      0.89      0.90       471\n",
      "\n",
      "    accuracy                           0.93      2947\n",
      "   macro avg       0.93      0.92      0.93      2947\n",
      "weighted avg       0.93      0.93      0.93      2947\n",
      "\n",
      "\n",
      "Model: GradientBoostingClassifier\n",
      "Accuracy: 93.96%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       537\n",
      "           1       0.93      0.86      0.89       491\n",
      "           2       0.88      0.94      0.91       532\n",
      "           3       0.94      0.98      0.96       496\n",
      "           4       0.97      0.92      0.95       420\n",
      "           5       0.93      0.93      0.93       471\n",
      "\n",
      "    accuracy                           0.94      2947\n",
      "   macro avg       0.94      0.94      0.94      2947\n",
      "weighted avg       0.94      0.94      0.94      2947\n",
      "\n",
      "\n",
      "Model: SVC\n",
      "Accuracy: 95.18%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       537\n",
      "           1       0.94      0.90      0.92       491\n",
      "           2       0.92      0.95      0.93       532\n",
      "           3       0.96      0.97      0.97       496\n",
      "           4       0.98      0.92      0.95       420\n",
      "           5       0.93      0.97      0.95       471\n",
      "\n",
      "    accuracy                           0.95      2947\n",
      "   macro avg       0.95      0.95      0.95      2947\n",
      "weighted avg       0.95      0.95      0.95      2947\n",
      "\n",
      "\n",
      "Model: KNeighborsClassifier\n",
      "Accuracy: 88.36%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       537\n",
      "           1       0.88      0.76      0.82       491\n",
      "           2       0.80      0.93      0.86       532\n",
      "           3       0.82      0.97      0.89       496\n",
      "           4       0.95      0.75      0.84       420\n",
      "           5       0.90      0.89      0.89       471\n",
      "\n",
      "    accuracy                           0.88      2947\n",
      "   macro avg       0.89      0.88      0.88      2947\n",
      "weighted avg       0.89      0.88      0.88      2947\n",
      "\n",
      "\n",
      "Training Neural Network...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devdr\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6752 - loss: 0.8680 - val_accuracy: 0.9409 - val_loss: 0.1588\n",
      "Epoch 2/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9200 - loss: 0.2174 - val_accuracy: 0.9300 - val_loss: 0.1875\n",
      "Epoch 3/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9534 - loss: 0.1351 - val_accuracy: 0.9286 - val_loss: 0.1896\n",
      "Epoch 4/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9632 - loss: 0.1049 - val_accuracy: 0.9375 - val_loss: 0.1670\n",
      "Epoch 5/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9664 - loss: 0.0978 - val_accuracy: 0.9456 - val_loss: 0.1344\n",
      "Epoch 6/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9679 - loss: 0.0870 - val_accuracy: 0.9422 - val_loss: 0.1560\n",
      "Epoch 7/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9728 - loss: 0.0752 - val_accuracy: 0.9470 - val_loss: 0.1509\n",
      "Epoch 8/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9780 - loss: 0.0548 - val_accuracy: 0.9409 - val_loss: 0.1847\n",
      "Epoch 9/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9784 - loss: 0.0637 - val_accuracy: 0.9456 - val_loss: 0.1768\n",
      "Epoch 10/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9798 - loss: 0.0641 - val_accuracy: 0.9375 - val_loss: 0.1417\n",
      "Epoch 11/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9751 - loss: 0.0624 - val_accuracy: 0.9436 - val_loss: 0.2080\n",
      "Epoch 12/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9788 - loss: 0.0502 - val_accuracy: 0.9449 - val_loss: 0.1502\n",
      "Epoch 13/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9841 - loss: 0.0462 - val_accuracy: 0.9449 - val_loss: 0.1629\n",
      "Epoch 14/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9857 - loss: 0.0379 - val_accuracy: 0.9524 - val_loss: 0.1577\n",
      "Epoch 15/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9814 - loss: 0.0544 - val_accuracy: 0.9551 - val_loss: 0.1319\n",
      "Epoch 16/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9834 - loss: 0.0423 - val_accuracy: 0.9483 - val_loss: 0.1831\n",
      "Epoch 17/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9822 - loss: 0.0444 - val_accuracy: 0.9429 - val_loss: 0.1913\n",
      "Epoch 18/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9857 - loss: 0.0439 - val_accuracy: 0.9504 - val_loss: 0.1731\n",
      "Epoch 19/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9833 - loss: 0.0447 - val_accuracy: 0.9483 - val_loss: 0.1573\n",
      "Epoch 20/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.0398 - val_accuracy: 0.9545 - val_loss: 0.1433\n",
      "Epoch 21/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9829 - loss: 0.0536 - val_accuracy: 0.9449 - val_loss: 0.1740\n",
      "Epoch 22/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9863 - loss: 0.0353 - val_accuracy: 0.9490 - val_loss: 0.1890\n",
      "Epoch 23/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9882 - loss: 0.0354 - val_accuracy: 0.9524 - val_loss: 0.1755\n",
      "Epoch 24/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9903 - loss: 0.0261 - val_accuracy: 0.9490 - val_loss: 0.1979\n",
      "Epoch 25/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0238 - val_accuracy: 0.9504 - val_loss: 0.1960\n",
      "Epoch 26/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.0171 - val_accuracy: 0.9483 - val_loss: 0.2161\n",
      "Epoch 27/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9902 - loss: 0.0343 - val_accuracy: 0.9531 - val_loss: 0.1783\n",
      "Epoch 28/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0208 - val_accuracy: 0.9538 - val_loss: 0.1899\n",
      "Epoch 29/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9882 - loss: 0.0370 - val_accuracy: 0.9504 - val_loss: 0.2432\n",
      "Epoch 30/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9940 - loss: 0.0167 - val_accuracy: 0.9497 - val_loss: 0.2590\n",
      "Epoch 31/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9866 - loss: 0.0499 - val_accuracy: 0.9579 - val_loss: 0.1596\n",
      "Epoch 32/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0214 - val_accuracy: 0.9497 - val_loss: 0.1917\n",
      "Epoch 33/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9921 - loss: 0.0236 - val_accuracy: 0.9517 - val_loss: 0.2690\n",
      "Epoch 34/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0208 - val_accuracy: 0.9524 - val_loss: 0.2292\n",
      "Epoch 35/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0215 - val_accuracy: 0.9551 - val_loss: 0.2888\n",
      "Epoch 36/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9892 - loss: 0.0251 - val_accuracy: 0.9524 - val_loss: 0.1862\n",
      "Epoch 37/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0302 - val_accuracy: 0.9497 - val_loss: 0.2176\n",
      "Epoch 38/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9934 - loss: 0.0217 - val_accuracy: 0.9470 - val_loss: 0.2582\n",
      "Epoch 39/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9950 - loss: 0.0132 - val_accuracy: 0.9511 - val_loss: 0.2120\n",
      "Epoch 40/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0215 - val_accuracy: 0.9565 - val_loss: 0.1735\n",
      "Epoch 41/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9911 - loss: 0.0309 - val_accuracy: 0.9483 - val_loss: 0.2287\n",
      "Epoch 42/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9894 - loss: 0.0333 - val_accuracy: 0.9517 - val_loss: 0.2312\n",
      "Epoch 43/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9954 - loss: 0.0155 - val_accuracy: 0.9449 - val_loss: 0.2592\n",
      "Epoch 44/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9950 - loss: 0.0126 - val_accuracy: 0.9538 - val_loss: 0.2597\n",
      "Epoch 45/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9890 - loss: 0.0418 - val_accuracy: 0.9483 - val_loss: 0.2635\n",
      "Epoch 46/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0127 - val_accuracy: 0.9572 - val_loss: 0.1844\n",
      "Epoch 47/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9950 - loss: 0.0133 - val_accuracy: 0.9483 - val_loss: 0.2428\n",
      "Epoch 48/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9942 - loss: 0.0242 - val_accuracy: 0.9497 - val_loss: 0.2445\n",
      "Epoch 49/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9927 - loss: 0.0269 - val_accuracy: 0.9524 - val_loss: 0.1943\n",
      "Epoch 50/50\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9935 - loss: 0.0199 - val_accuracy: 0.9545 - val_loss: 0.2027\n",
      "\n",
      "Model: Neural Network\n",
      "Accuracy: 93.32%\n",
      "\n",
      "Model Accuracies:\n",
      "LogisticRegression: 95.45%\n",
      "RandomForestClassifier: 92.67%\n",
      "GradientBoostingClassifier: 93.96%\n",
      "SVC: 95.18%\n",
      "KNeighborsClassifier: 88.36%\n",
      "Neural Network: 93.32%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the data\n",
    "train_csv = \"train.csv\"\n",
    "test_csv = \"test.csv\"\n",
    "train = pd.read_csv(train_csv)\n",
    "test = pd.read_csv(test_csv)\n",
    "\n",
    "# Inspect the data\n",
    "print(\"Columns in the dataset:\", train.columns)\n",
    "print(\"Number of columns:\", len(train.columns))\n",
    "\n",
    "# Separate features and labels\n",
    "X_train = train.iloc[:, :-2]  # Exclude 'subject' and 'Activity'\n",
    "X_test = test.iloc[:, :-2]\n",
    "y_train = train['Activity']\n",
    "y_test = test['Activity']\n",
    "\n",
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Store model accuracies\n",
    "model_accuracies = []\n",
    "\n",
    "# Define and evaluate different models\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"\\nModel: {model.__class__.__name__}\")\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n",
    "    model_accuracies.append((model.__class__.__name__, accuracy))\n",
    "    return accuracy\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "evaluate_model(log_reg, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "evaluate_model(rf, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Gradient Boosting\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "evaluate_model(gb, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Support Vector Machine\n",
    "svm = SVC(kernel='rbf', probability=True)\n",
    "evaluate_model(svm, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "evaluate_model(knn, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Neural Network\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train_nn = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_nn = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "nn = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "nn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"\\nTraining Neural Network...\")\n",
    "nn.fit(X_train, y_train_nn, epochs=50, batch_size=32, verbose=1, validation_split=0.2)\n",
    "\n",
    "# Evaluate Neural Network\n",
    "nn_loss, nn_accuracy = nn.evaluate(X_test, y_test_nn, verbose=0)\n",
    "print(f\"\\nModel: Neural Network\")\n",
    "print(f\"Accuracy: {nn_accuracy * 100:.2f}%\")\n",
    "model_accuracies.append((\"Neural Network\", nn_accuracy))\n",
    "\n",
    "# Print model accuracies\n",
    "print(\"\\nModel Accuracies:\")\n",
    "for model_name, accuracy in model_accuracies:\n",
    "    print(f\"{model_name}: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
